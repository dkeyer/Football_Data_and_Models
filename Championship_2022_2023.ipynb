{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0298f0",
   "metadata": {},
   "source": [
    "# Getting Game IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb9c4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://fbref.com/en/comps/10/2022-2023/schedule/2022-2023-Championship-Scores-and-Fixtures\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all <td> elements with data-stat=\"score\"\n",
    "score_cells = soup.find_all('td', {'data-stat': 'score'})\n",
    "\n",
    "# Extract game IDs from the <a> tags within the score_cells, the third element is the game ID\n",
    "game_ids = [cell.find('a')['href'].split('/')[3] for cell in score_cells if cell.find('a')]\n",
    "# Then strip the white space in the IDs\n",
    "game_ids = [x.strip(' ') for x in game_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7fe6c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids = game_ids[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b468b7",
   "metadata": {},
   "source": [
    "# Scraping Shot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "669a070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_data = []\n",
    "for unique_id in game_ids:\n",
    "    # URL of the page to scrape\n",
    "    url = f'https://fbref.com/en/matches/{unique_id}/'\n",
    "\n",
    "    # Get the game ID from the URL\n",
    "    game_id = url.split(\"/\")[-2]\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the Shots table on the page\n",
    "    shots_table = soup.find(\"div\", {\"id\": \"switcher_shots\"})\n",
    "\n",
    "    # Create empty lists to store data and create the columns\n",
    "    data = []\n",
    "    headers = ['Game_ID', 'Minute', 'Player', 'Team', 'xG', 'PSxG', 'Result', 'Distance', 'Body Part', 'Notes', 'SCA 1 Player', 'Event 1', 'SCA 2 Player', 'Event 2']\n",
    "\n",
    "    # Extract table rows\n",
    "    rows = shots_table.find(\"tbody\").find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        row_data = [game_id] + [cell.get_text().strip() for cell in row.find_all([\"th\", \"td\"])]\n",
    "        data.append(row_data)\n",
    "\n",
    "    # Create a DataFrame from the scraped data\n",
    "    shots_df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "    # Find the home and away teams and formations\n",
    "    team_headers = soup.find_all(\"th\", {\"colspan\": \"2\"})\n",
    "    teams = [header.text.strip().split(\" (\")[0] for header in team_headers if \"(\" in header.text.strip()]\n",
    "    formations = [header.text.strip().split(\" (\")[1][:-1] for header in team_headers if \"(\" in header.text.strip()]\n",
    "\n",
    "    # Extracting the home and away teams and formations\n",
    "    home_team = teams[0]\n",
    "    away_team = teams[1]\n",
    "    home_formation = formations[0]\n",
    "    away_formation = formations[1]\n",
    "\n",
    "    # Find the competition -- only using .find because there are multiple in the HTML and we only need one, then take only the text\n",
    "    competition = soup.find(\"a\", {\"href\": \"/en/comps/10/2022-2023/2022-2023-Championship-Stats\"}).text\n",
    "\n",
    "    # Extract the match date and add to df, this one is a little tricky as it's hidden within the span tag\n",
    "    span_venuetime = soup.find(\"span\", class_=\"venuetime\")\n",
    "    match_date = span_venuetime.get(\"data-venue-date\") if span_venuetime else None\n",
    "\n",
    "    #Get location, 4th element in that list\n",
    "    location = soup.find(\"div\", {\"class\": \"scorebox_meta\"}).find_all(\"small\")[3].text\n",
    "    \n",
    "    all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b233e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten list one level to load into df\n",
    "all_data = sum(all_data, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ecbe661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is one row in each shots table on FBREF that is completely blank, so we can remove that before we load lists into the df\n",
    "#This logic says if the minute, player, and team columns are blank (doing three to be safe), we can drop the record\n",
    "for i in all_data:\n",
    "    if i[1] == '' and i[2] == '' and i[3] == '':\n",
    "        all_data.remove(i)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dc6e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the scraped data\n",
    "shots_df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "# Add the team, away team, formation, and opponent formation information to the DataFrame\n",
    "shots_df['Home_Team'] = home_team\n",
    "shots_df['Away_Team'] = away_team\n",
    "shots_df['Home Formation'] = home_formation\n",
    "shots_df['Away Formation'] = away_formation\n",
    "shots_df['is_home_shot'] = np.where(shots_df['Team'] == home_team, 1, 0)\n",
    "shots_df['is_away_shot'] = np.where(shots_df['Team'] ==  away_team, 1, 0)\n",
    "shots_df['location'] = location\n",
    "shots_df['match_date'] = match_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d55cab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#other leagues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
