{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b1a92e",
   "metadata": {},
   "source": [
    "# Get League Table and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ef5e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40e2aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FBRef URL\n",
    "url = \"https://fbref.com/en/comps/10/Championship-Stats\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "    # Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the table using its HTML class\n",
    "table = soup.find(\"table\", {\"class\": \"stats_table\"})\n",
    "\n",
    "    # Extract table data into a list of lists\n",
    "table_data = []\n",
    "for row in table.find_all(\"tr\"):\n",
    "    row_data = [cell.text.strip() for cell in row.find_all([\"th\", \"td\"])]\n",
    "    table_data.append(row_data)\n",
    "\n",
    "    # Create a DataFrame from the list of lists\n",
    "columns = table_data[0]  # Assuming the first row contains column headers\n",
    "data = table_data[1:]\n",
    "league_table_df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aec7984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure we are getting a response\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475585bc",
   "metadata": {},
   "source": [
    "# Get Fixtures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32813dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the website\n",
    "url = \"https://fbref.com/en/comps/10/schedule/Championship-Scores-and-Fixtures\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the table containing fixtures\n",
    "    table = soup.find(\"table\", {\"class\": \"stats_table\"})\n",
    "\n",
    "    # Extract data into a list of dictionaries\n",
    "    fixtures_data = []\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip the header row\n",
    "        columns = row.find_all([\"th\", \"td\"])\n",
    "        \n",
    "         # Extracting specific columns based on the structure of the table\n",
    "        fixture_type = columns[0].text.strip()\n",
    "        gameweek = columns[1].text.strip()\n",
    "        day_of_week = columns[2].text.strip()\n",
    "        date = columns[3].text.strip()\n",
    "        match_time = columns[4].text.strip()\n",
    "        home_team = columns[5].text.strip()\n",
    "        home_xG = columns[6].text.strip()\n",
    "        result = columns[7].text.strip()\n",
    "        away_xG = columns[8].text.strip()\n",
    "        away_team = columns[9].text.strip()\n",
    "        attendance = columns[10].text.strip()\n",
    "        stadium = columns[11].text.strip()\n",
    "        referee = columns[12].text.strip()\n",
    "\n",
    "        fixture_info = {\n",
    "            \"fixture_type\": fixture_type,\n",
    "            \"gameweek\": gameweek,\n",
    "            \"day_of_week\": day_of_week,\n",
    "            \"date\": date,\n",
    "            \"match_time\": match_time,\n",
    "            \"home_team\": home_team,\n",
    "            \"home_xG\": home_xG,\n",
    "            \"result\": result,\n",
    "            \"away_xG\": away_xG,\n",
    "            \"away_team\": away_team,\n",
    "            \"attendance\": attendance,\n",
    "            \"stadium\": stadium,\n",
    "            \"referee\": referee\n",
    "        }\n",
    "\n",
    "        fixtures_data.append(fixture_info)\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    fixtures_table = pd.DataFrame(fixtures_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "214bbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixtures_table['is_game_complete'] = np.where(len(fixtures_table['result']) > 0, 1, 0)\n",
    "# Checking to see if game is complete... if the result column is populated at all, it's been played "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2471532f",
   "metadata": {},
   "source": [
    "# Getting Game IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb9c4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the website\n",
    "url = \"https://fbref.com/en/comps/10/schedule/Championship-Scores-and-Fixtures\"\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all <td> elements with data-stat=\"score\"\n",
    "score_cells = soup.find_all('td', {'data-stat': 'score'})\n",
    "\n",
    "# Extract game IDs from the <a> tags within the score_cells, the third element is the game ID\n",
    "game_ids = [cell.find('a')['href'].split('/')[3].strip() for cell in score_cells if cell.find('a')]\n",
    "\n",
    "# Use a set to ensure uniqueness and convert back to a list\n",
    "game_ids = list(set(game_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1395c59",
   "metadata": {},
   "source": [
    "# Scraping Shot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669a070c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "for unique_id in game_ids:\n",
    "    # URL of the page to scrape\n",
    "    url = f'https://fbref.com/en/matches/{unique_id}/'\n",
    "\n",
    "    # Get the game ID from the URL\n",
    "    game_id = url.split(\"/\")[-2]\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the Shots table on the page\n",
    "    shots_table = soup.find(\"div\", {\"id\": \"switcher_shots\"})\n",
    "\n",
    "    # Create empty lists to store data and create the columns\n",
    "    data = []\n",
    "    headers = ['game_id', 'minute', 'player', 'team', 'xG', 'psxG', 'result', 'distance', 'body_part', 'notes', 'sca_1_player', 'event_1', 'sca_2_player', 'event_2']\n",
    "\n",
    "    # Extract table rows\n",
    "    rows = shots_table.find(\"tbody\").find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        row_data = [game_id] + [cell.get_text().strip() for cell in row.find_all([\"th\", \"td\"])]\n",
    "        data.append(row_data)\n",
    "\n",
    "    # Find the home and away teams and formations\n",
    "    team_headers = soup.find_all(\"th\", {\"colspan\": \"2\"})\n",
    "    teams = [header.text.strip().split(\" (\")[0] for header in team_headers if \"(\" in header.text.strip()]\n",
    "    formations = [header.text.strip().split(\" (\")[1][:-1] for header in team_headers if \"(\" in header.text.strip()]\n",
    "\n",
    "    # Extracting the home and away teams and formations\n",
    "    home_team = teams[0]\n",
    "    away_team = teams[1]\n",
    "    home_formation = formations[0]\n",
    "    away_formation = formations[1]\n",
    "\n",
    "    # Find the location and match date\n",
    "    location = soup.find(\"div\", {\"class\": \"scorebox_meta\"}).find_all(\"small\")[3].text\n",
    "    match_date = soup.find(\"span\", class_=\"venuetime\").get(\"data-venue-date\", None)\n",
    "\n",
    "    # Append additional columns to headers\n",
    "    headers.extend(['home_team', 'away_team', 'home_formation', 'away_formation', 'location', 'match_date'])\n",
    "\n",
    "    # Append data to all_data with additional columns\n",
    "    for row in data:\n",
    "        row.extend([home_team, away_team, home_formation, away_formation, location, match_date])\n",
    "        all_data.append(row)\n",
    "        \n",
    "        \n",
    "    time.sleep(15)\n",
    "        \n",
    "# Create a DataFrame from the scraped data\n",
    "shots_df = pd.DataFrame(all_data, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1995eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Home and away shots, location, hard-code competition\n",
    "shots_df['is_home_shot'] = np.where(shots_df['team'] == shots_df['home_team'], 1, 0)\n",
    "shots_df['is_away_shot'] = np.where(shots_df['team'] ==  shots_df['away_team'], 1, 0)\n",
    "shots_df['competition'] = 'English Championship'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1a93f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate total score for each game\n",
    "def calculate_total_score(group, shot):\n",
    "    total_score = 0\n",
    "    total_scores = []\n",
    "\n",
    "    # Flag to indicate whether the current row is after a 'Goal'\n",
    "    after_goal = False\n",
    "\n",
    "    for idx, (result, is_shot) in enumerate(zip(group, shot)):\n",
    "        # Check if the current row is after a 'Goal'\n",
    "        if after_goal:\n",
    "            # Increment the total score\n",
    "            total_score += 1\n",
    "            # Reset the flag\n",
    "            after_goal = False\n",
    "\n",
    "        # Check if the current result is 'Goal' and the corresponding shot is 1\n",
    "        if result == 'Goal' and is_shot == 1:\n",
    "            # Set the flag to True for the next iteration\n",
    "            after_goal = True\n",
    "        \n",
    "        # Append the current total score\n",
    "        total_scores.append(total_score)\n",
    "\n",
    "    return total_scores\n",
    "\n",
    "# Group by game_id and apply the function to calculate total score for home team\n",
    "shots_df['home_score'] = shots_df.groupby('game_id')['result'].transform(lambda x: calculate_total_score(x, shots_df['is_home_shot']))\n",
    "\n",
    "# Group by game_id and apply the function to calculate total score for away team\n",
    "shots_df['away_score'] = shots_df.groupby('game_id')['result'].transform(lambda x: calculate_total_score(x, shots_df['is_away_shot']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1312683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a nil nil column using numpy where and logical_and operators\n",
    "shots_df['is_nil_nil'] = np.where(np.logical_and(shots_df['home_score'] == 0, shots_df['away_score'] == 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "193e8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding opposing team -- Whenever it's a home shot we want the away team, otherwise (away shot) we want the home team\n",
    "shots_df['opposing_team'] = np.where(shots_df['is_home_shot'] == 1, shots_df['away_team'], shots_df['home_team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e4306cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace blank values with nulls\n",
    "shots_df['xG'] = shots_df['xG'].replace('', np.nan)\n",
    "\n",
    "# Then drop them\n",
    "shots_df = shots_df.dropna(subset=['xG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb84d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast xG as float\n",
    "shots_df['xG'] = shots_df['xG'].astype('float64') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c6ed6",
   "metadata": {},
   "source": [
    "# Adding xG and xGA while nil-nil to league_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ef122ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter shots_df where is_nil_nil is 0\n",
    "filtered_shots_df = shots_df[shots_df['is_nil_nil'] == 1]\n",
    "\n",
    "# Calculate the sum of 'xG' for each 'team'\n",
    "team_xG_sum = filtered_shots_df.groupby('team')['xG'].sum().reset_index()\n",
    "\n",
    "# Create a dictionary to map team names to their respective summed 'xG' values\n",
    "team_xG_dict = dict(zip(team_xG_sum['team'], team_xG_sum['xG']))\n",
    "\n",
    "# Add 'nil_nil_xG' column to league_table_df by mapping team names to their summed 'xG' values\n",
    "league_table_df['nil_nil_xG'] = league_table_df['Squad'].map(team_xG_dict)\n",
    "\n",
    "# Fill NaN values with 0 if any team didn't have any 'xG' when is_nil_nil is 0\n",
    "league_table_df['nil_nil_xG'].fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the sum of 'xGA' for each 'team'\n",
    "team_xGA_sum = filtered_shots_df.groupby('opposing_team')['xG'].sum().reset_index()\n",
    "\n",
    "# Create a dictionary to map team names to their respective summed 'xGA' values -- AKA xG of opposing_team\n",
    "team_xGA_dict = dict(zip(team_xGA_sum['opposing_team'], team_xGA_sum['xG']))\n",
    "\n",
    "# Add 'nil_nil_xGA' column to league_table_df by mapping team names to their summed 'xGA' values\n",
    "league_table_df['nil_nil_xGA'] = league_table_df['Squad'].map(team_xGA_dict)\n",
    "\n",
    "# Fill NaN values with 0 if any team didn't have any 'xG' when is_nil_nil is 0\n",
    "league_table_df['nil_nil_xGA'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a0f4214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting datatypes\n",
    "league_table_df = league_table_df.astype({\"MP\": int, \"W\": int, \"D\": int, \"L\": int, \"GF\": int, \"GD\": int, \"Pts\": int, \"Pts/MP\": float\n",
    "                                         , \"xG\": float, \"xGA\": float, \"xGD\": float, \"xGD/90\": float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd70c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating xG per match feature, rounding, adding + to positive values\n",
    "league_table_df['nil_nil_xG_diff'] = round((league_table_df['nil_nil_xG'] - league_table_df['nil_nil_xGA']) / league_table_df['MP'], 3)\n",
    "\n",
    "league_table_df = league_table_df.style.format({'nil_nil_xG_diff':\"{0:+g}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7b95d58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Export CSV to 'Data' repo\n",
    "league_table_df.to_csv(r'C:\\Users\\User\\dave_desktop\\football_coding\\data\\championship_data_2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2860a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a98ffadb",
   "metadata": {},
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d678d",
   "metadata": {},
   "source": [
    "1. Add formation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e5604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
