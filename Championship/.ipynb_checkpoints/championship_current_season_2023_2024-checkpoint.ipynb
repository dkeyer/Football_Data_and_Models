{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b1a92e",
   "metadata": {},
   "source": [
    "# Get League Table and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8ef5e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40e2aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the website\n",
    "url = \"https://fbref.com/en/comps/10/Championship-Stats\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "    # Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the table using its HTML class\n",
    "table = soup.find(\"table\", {\"class\": \"stats_table\"})\n",
    "\n",
    "    # Extract table data into a list of lists\n",
    "table_data = []\n",
    "for row in table.find_all(\"tr\"):\n",
    "    row_data = [cell.text.strip() for cell in row.find_all([\"th\", \"td\"])]\n",
    "    table_data.append(row_data)\n",
    "\n",
    "    # Create a DataFrame from the list of lists\n",
    "columns = table_data[0]  # Assuming the first row contains column headers\n",
    "data = table_data[1:]\n",
    "league_table_df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475585bc",
   "metadata": {},
   "source": [
    "# Get Fixtures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32813dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the website\n",
    "url = \"https://fbref.com/en/comps/10/schedule/Championship-Scores-and-Fixtures\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the table containing fixtures\n",
    "    table = soup.find(\"table\", {\"class\": \"stats_table\"})\n",
    "\n",
    "    # Extract data into a list of dictionaries\n",
    "    fixtures_data = []\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip the header row\n",
    "        columns = row.find_all([\"th\", \"td\"])\n",
    "        \n",
    "         # Extracting specific columns based on the structure of the table\n",
    "        fixture_type = columns[0].text.strip()\n",
    "        matchday = columns[1].text.strip()\n",
    "        weekday = columns[2].text.strip()\n",
    "        date = columns[3].text.strip()\n",
    "        time = columns[4].text.strip()\n",
    "        home_team = columns[5].text.strip()\n",
    "        home_xG = columns[6].text.strip()\n",
    "        result = columns[7].text.strip()\n",
    "        away_team = columns[8].text.strip()\n",
    "        away_xG = columns[9].text.strip()\n",
    "        attendance = columns[10].text.strip()\n",
    "        stadium = columns[11].text.strip()\n",
    "        referee = columns[12].text.strip()\n",
    "\n",
    "        fixture_info = {\n",
    "            \"fixture_type\": fixture_type,\n",
    "            \"matchday\": matchday,\n",
    "            \"weekday\": weekday,\n",
    "            \"date\": date,\n",
    "            \"time\": time,\n",
    "            \"home_team\": home_team,\n",
    "            \"home_xG\": home_xG,\n",
    "            \"result\": result,\n",
    "            \"away_xG\": away_xG,\n",
    "            \"away_team\": away_team,\n",
    "            \"attendance\": attendance,\n",
    "            \"stadium\": stadium,\n",
    "            \"referee\": referee\n",
    "        }\n",
    "\n",
    "        fixtures_data.append(fixture_info)\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    fixtures_table = pd.DataFrame(fixtures_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3777001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixture_type</th>\n",
       "      <th>matchday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>home_team</th>\n",
       "      <th>home_xG</th>\n",
       "      <th>result</th>\n",
       "      <th>away_xG</th>\n",
       "      <th>away_team</th>\n",
       "      <th>attendance</th>\n",
       "      <th>stadium</th>\n",
       "      <th>referee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Sheffield Weds</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1–2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>28,558</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Hillsborough Stadium</td>\n",
       "      <td>Robert Madley</td>\n",
       "      <td>Match Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Bristol City</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1–1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>29,359</td>\n",
       "      <td>Preston</td>\n",
       "      <td>Ashton Gate Stadium</td>\n",
       "      <td>David Webb</td>\n",
       "      <td>Match Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Plymouth Argyle</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3–1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16,446</td>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>Home Park</td>\n",
       "      <td>Matt Donohue</td>\n",
       "      <td>Match Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Stoke City</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4–1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>22,601</td>\n",
       "      <td>Rotherham Utd</td>\n",
       "      <td>Bet365 Stadium</td>\n",
       "      <td>John Busby</td>\n",
       "      <td>Match Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0–1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>29,359</td>\n",
       "      <td>Millwall</td>\n",
       "      <td>Riverside Stadium</td>\n",
       "      <td>Gavin Ward</td>\n",
       "      <td>Match Report</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fixture_type matchday     weekday   date             time home_team home_xG  \\\n",
       "0            1      Fri  2023-08-04  20:00   Sheffield Weds       0.5     1–2   \n",
       "1            1      Sat  2023-08-05  15:00     Bristol City       0.9     1–1   \n",
       "2            1      Sat  2023-08-05  15:00  Plymouth Argyle       2.4     3–1   \n",
       "3            1      Sat  2023-08-05  15:00       Stoke City       2.4     4–1   \n",
       "4            1      Sat  2023-08-05  15:00    Middlesbrough       0.8     0–1   \n",
       "\n",
       "  result away_xG      away_team            attendance        stadium  \\\n",
       "0    1.4  28,558    Southampton  Hillsborough Stadium  Robert Madley   \n",
       "1    1.3  29,359        Preston   Ashton Gate Stadium     David Webb   \n",
       "2    2.0  16,446   Huddersfield             Home Park   Matt Donohue   \n",
       "3    0.9  22,601  Rotherham Utd        Bet365 Stadium     John Busby   \n",
       "4    1.2  29,359       Millwall     Riverside Stadium     Gavin Ward   \n",
       "\n",
       "        referee  \n",
       "0  Match Report  \n",
       "1  Match Report  \n",
       "2  Match Report  \n",
       "3  Match Report  \n",
       "4  Match Report  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixtures_table.head()\n",
    "#need to fix from attendance on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "214bbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixtures_table['is_game_complete'] = np.where(len(fixtures_table['result']) > 0, 1, 0)\n",
    "#Checking to see if game is complete... if the result column is populated at all, it's beem played"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2471532f",
   "metadata": {},
   "source": [
    "# Getting Game IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb9c4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the website\n",
    "url = \"https://fbref.com/en/comps/10/schedule/Championship-Scores-and-Fixtures\"\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all <td> elements with data-stat=\"score\"\n",
    "score_cells = soup.find_all('td', {'data-stat': 'score'})\n",
    "\n",
    "# Extract game IDs from the <a> tags within the score_cells, the third element is the game ID\n",
    "game_ids = [cell.find('a')['href'].split('/')[3] for cell in score_cells if cell.find('a')]\n",
    "# Then strip the white space in the IDs\n",
    "game_ids = [x.strip(' ') for x in game_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae5d02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids = game_ids[0:4]\n",
    "#just use three to test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1395c59",
   "metadata": {},
   "source": [
    "# Scraping Shot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "669a070c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for unique_id in game_ids:\n",
    "    # URL of the page to scrape\n",
    "    url = f'https://fbref.com/en/matches/{unique_id}/'\n",
    "\n",
    "    # Get the game ID from the URL\n",
    "    game_id = url.split(\"/\")[-2]\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the Shots table on the page\n",
    "    shots_table = soup.find(\"div\", {\"id\": \"switcher_shots\"})\n",
    "\n",
    "    # Create empty lists to store data and create the columns\n",
    "    data = []\n",
    "    headers = ['Game_ID', 'Minute', 'Player', 'Team', 'xG', 'PSxG', 'Result', 'Distance', 'Body Part', 'Notes', 'SCA 1 Player', 'Event 1', 'SCA 2 Player', 'Event 2']\n",
    "\n",
    "    # Extract table rows\n",
    "    rows = shots_table.find(\"tbody\").find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        row_data = [game_id] + [cell.get_text().strip() for cell in row.find_all([\"th\", \"td\"])]\n",
    "        data.append(row_data)\n",
    "\n",
    "    # Create a DataFrame from the scraped data\n",
    "    shots_df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "    # Find the home and away teams and formations\n",
    "    team_headers = soup.find_all(\"th\", {\"colspan\": \"2\"})\n",
    "    teams = [header.text.strip().split(\" (\")[0] for header in team_headers if \"(\" in header.text.strip()]\n",
    "    formations = [header.text.strip().split(\" (\")[1][:-1] for header in team_headers if \"(\" in header.text.strip()]\n",
    "\n",
    "    # Extracting the home and away teams and formations\n",
    "    home_team = teams[0]\n",
    "    away_team = teams[1]\n",
    "    home_formation = formations[0]\n",
    "    away_formation = formations[1]\n",
    "\n",
    "    # Find the competition -- only using .find because there are multiple in the HTML and we only need one, then take only the text\n",
    "    #competition = soup.find(\"a\", {\"href\": \"/en/comps/10/2022-2023/2022-2023-Championship-Stats\"}).text\n",
    "    #Don't need this competition anymore... fine to hardcode it since within every notebook it will be the same\n",
    "\n",
    "    # Extract the match date and add to df, this one is a little tricky as it's hidden within the span tag\n",
    "    span_venuetime = soup.find(\"span\", class_=\"venuetime\")\n",
    "    match_date = span_venuetime.get(\"data-venue-date\") if span_venuetime else None\n",
    "\n",
    "    #Get location, 4th element in that list\n",
    "    location = soup.find(\"div\", {\"class\": \"scorebox_meta\"}).find_all(\"small\")[3].text\n",
    "    \n",
    "    all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60945f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten list one level to load into df\n",
    "all_data = sum(all_data, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c56187de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the scraped data\n",
    "shots_df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "# Add the team, away team, formation, and opponent formation information to the DataFrame\n",
    "shots_df['Home_Team'] = home_team\n",
    "shots_df['Away_Team'] = away_team\n",
    "shots_df['Home Formation'] = home_formation\n",
    "shots_df['Away Formation'] = away_formation\n",
    "shots_df['is_home_shot'] = np.where(shots_df['Team'] == home_team, 1, 0)\n",
    "shots_df['is_away_shot'] = np.where(shots_df['Team'] ==  away_team, 1, 0)\n",
    "shots_df['location'] = location\n",
    "shots_df['match_date'] = match_date\n",
    "shots_df['competition'] = 'English Championship'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ffadb",
   "metadata": {},
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d678d",
   "metadata": {},
   "source": [
    "1a. In competition -- get the correct url dynamically\n",
    "1. EDA\n",
    "2. Start Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f448e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
