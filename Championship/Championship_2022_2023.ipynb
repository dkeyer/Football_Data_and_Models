{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b1a92e",
   "metadata": {},
   "source": [
    "# Get League Table and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e2aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "url = \"https://fbref.com/en/comps/10/2022-2023/2022-2023-Championship-Stats\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "    # Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the table using its HTML class\n",
    "table = soup.find(\"table\", {\"class\": \"stats_table\"})\n",
    "\n",
    "    # Extract table data into a list of lists\n",
    "table_data = []\n",
    "for row in table.find_all(\"tr\"):\n",
    "    row_data = [cell.text.strip() for cell in row.find_all([\"th\", \"td\"])]\n",
    "    table_data.append(row_data)\n",
    "\n",
    "    # Create a DataFrame from the list of lists\n",
    "columns = table_data[0]  # Assuming the first row contains column headers\n",
    "data = table_data[1:]\n",
    "league_table_df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475585bc",
   "metadata": {},
   "source": [
    "# Get Fixtures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32813dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get main table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2471532f",
   "metadata": {},
   "source": [
    "# Getting Fixtures and Game IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb9c4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://fbref.com/en/comps/10/2022-2023/schedule/2022-2023-Championship-Scores-and-Fixtures\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all <td> elements with data-stat=\"score\"\n",
    "score_cells = soup.find_all('td', {'data-stat': 'score'})\n",
    "\n",
    "# Extract game IDs from the <a> tags within the score_cells, the third element is the game ID\n",
    "game_ids = [cell.find('a')['href'].split('/')[3] for cell in score_cells if cell.find('a')]\n",
    "# Then strip the white space in the IDs\n",
    "game_ids = [x.strip(' ') for x in game_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae5d02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids = game_ids[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b6d318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['46d9048f', '03cea9be', '78f52c96']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "486d3299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date Home Team Away Team       Score\n",
      "0    Regular season         1       Fri  2022-07-29\n",
      "1    Regular season         1       Sat  2022-07-30\n",
      "2    Regular season         1       Sat  2022-07-30\n",
      "3    Regular season         1       Sat  2022-07-30\n",
      "4    Regular season         1       Sat  2022-07-30\n",
      "..              ...       ...       ...         ...\n",
      "612     Semi-finals                 Sat  2023-05-13\n",
      "613     Semi-finals                 Sun  2023-05-14\n",
      "614     Semi-finals                 Tue  2023-05-16\n",
      "615     Semi-finals                 Wed  2023-05-17\n",
      "616           Final                 Sat  2023-05-27\n",
      "\n",
      "[617 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the table containing scores and fixtures\n",
    "    table = soup.find(\"table\", {\"class\": \"stats_table\"})\n",
    "\n",
    "    # Extract data into a list of dictionaries\n",
    "    fixtures_data = []\n",
    "    for row in table.find_all(\"tr\")[1:]:  # Skip the header row\n",
    "        columns = row.find_all([\"th\", \"td\"])\n",
    "        fixture_date = columns[0].text.strip()\n",
    "        home_team = columns[1].text.strip()\n",
    "        away_team = columns[2].text.strip()\n",
    "        score = columns[3].text.strip()\n",
    "\n",
    "        fixture_info = {\n",
    "            \"Date\": fixture_date,\n",
    "            \"Home Team\": home_team,\n",
    "            \"Away Team\": away_team,\n",
    "            \"Score\": score\n",
    "        }\n",
    "\n",
    "        fixtures_data.append(fixture_info)\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(fixtures_data)\n",
    "\n",
    "    # Now, you have a DataFrame called 'df' with the scores and fixtures data\n",
    "    print(df)\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1395c59",
   "metadata": {},
   "source": [
    "# Scraping Shot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669a070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_data = []\n",
    "for unique_id in game_ids:\n",
    "    # URL of the page to scrape\n",
    "    url = f'https://fbref.com/en/matches/{unique_id}/'\n",
    "\n",
    "    # Get the game ID from the URL\n",
    "    game_id = url.split(\"/\")[-2]\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the Shots table on the page\n",
    "    shots_table = soup.find(\"div\", {\"id\": \"switcher_shots\"})\n",
    "\n",
    "    # Create empty lists to store data and create the columns\n",
    "    data = []\n",
    "    headers = ['Game_ID', 'Minute', 'Player', 'Team', 'xG', 'PSxG', 'Result', 'Distance', 'Body Part', 'Notes', 'SCA 1 Player', 'Event 1', 'SCA 2 Player', 'Event 2']\n",
    "\n",
    "    # Extract table rows\n",
    "    rows = shots_table.find(\"tbody\").find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        row_data = [game_id] + [cell.get_text().strip() for cell in row.find_all([\"th\", \"td\"])]\n",
    "        data.append(row_data)\n",
    "\n",
    "    # Create a DataFrame from the scraped data\n",
    "    shots_df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "    # Find the home and away teams and formations\n",
    "    team_headers = soup.find_all(\"th\", {\"colspan\": \"2\"})\n",
    "    teams = [header.text.strip().split(\" (\")[0] for header in team_headers if \"(\" in header.text.strip()]\n",
    "    formations = [header.text.strip().split(\" (\")[1][:-1] for header in team_headers if \"(\" in header.text.strip()]\n",
    "\n",
    "    # Extracting the home and away teams and formations\n",
    "    home_team = teams[0]\n",
    "    away_team = teams[1]\n",
    "    home_formation = formations[0]\n",
    "    away_formation = formations[1]\n",
    "\n",
    "    # Find the competition -- only using .find because there are multiple in the HTML and we only need one, then take only the text\n",
    "    competition = soup.find(\"a\", {\"href\": \"/en/comps/10/2022-2023/2022-2023-Championship-Stats\"}).text\n",
    "\n",
    "    # Extract the match date and add to df, this one is a little tricky as it's hidden within the span tag\n",
    "    span_venuetime = soup.find(\"span\", class_=\"venuetime\")\n",
    "    match_date = span_venuetime.get(\"data-venue-date\") if span_venuetime else None\n",
    "\n",
    "    #Get location, 4th element in that list\n",
    "    location = soup.find(\"div\", {\"class\": \"scorebox_meta\"}).find_all(\"small\")[3].text\n",
    "    \n",
    "    all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60945f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten list one level to load into df\n",
    "all_data = sum(all_data, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c56187de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the scraped data\n",
    "shots_df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "# Add the team, away team, formation, and opponent formation information to the DataFrame\n",
    "shots_df['Home_Team'] = home_team\n",
    "shots_df['Away_Team'] = away_team\n",
    "shots_df['Home Formation'] = home_formation\n",
    "shots_df['Away Formation'] = away_formation\n",
    "shots_df['is_home_shot'] = np.where(shots_df['Team'] == home_team, 1, 0)\n",
    "shots_df['is_away_shot'] = np.where(shots_df['Team'] ==  away_team, 1, 0)\n",
    "shots_df['location'] = location\n",
    "shots_df['match_date'] = match_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98abc110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a98ffadb",
   "metadata": {},
   "source": [
    "# To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d678d",
   "metadata": {},
   "source": [
    "1. Get fixtures\n",
    "2. Get overview game data\n",
    "3. EDA\n",
    "4. Start Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34deaf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
